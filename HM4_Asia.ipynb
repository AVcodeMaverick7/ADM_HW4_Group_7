{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient, collection\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen as ureq\n",
    "import re\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting MongoDB parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adm_hm4'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient()\n",
    "my_key = \"AnqLqo5TT9JDfzfqKrDUEYUqJ6HWZJy8\"\n",
    "base = \"https://api.mlab.com/api/1\"\n",
    "url_db = base + \"/databases?apiKey=\" + my_key\n",
    "response = requests.get(url_db)\n",
    "databases = json.loads(response.text)\n",
    "adm_database = databases[0]\n",
    "adm_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set structure for database\n",
    "headers = {'content-type':'application/json'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We manually created the collection 'flats' in the \"adm_hm4\" database (MongoDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = 'flats'\n",
    "col_url = base + '/databases/' + adm_database + \"/collections/\" + collection +'/?apiKey=' + my_key\n",
    "\n",
    "# Pushing data into database\n",
    "# payload = json.dumps(flat_data)\n",
    "# response = requests.post(col_url, data=payload, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we extract the interesting data from websites and push into our database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_data(soup):\n",
    "    \"\"\" \n",
    "    This function is retrieving data about : price, locali, superficie, bagni, piano.\n",
    "    Input: The Beautiful Soup object.\n",
    "    Output: The dictionary object with integer values. \n",
    "    \"\"\"\n",
    "    # find the html tag with price\n",
    "    price = soup.find_all('li',class_='features__price')[0].get_text()\n",
    "    # extract and preprocess string to get price\n",
    "    price = price.replace(\"â‚¬\", \"\").replace(\" \", \"\").replace(\".\", \"\")\n",
    "    # find the html tag with the info about: locali, superficie, bagni, piano\n",
    "    data = soup.find_all('ul','list-inline list-piped features__list')[0].get_text()\n",
    "    # preprocess string and find numbers\n",
    "    data = data.replace('m2','')\n",
    "    numbers = re.compile('\\d+(?:\\.\\d+)?')\n",
    "    data = numbers.findall(data)\n",
    "    # if found all numbers -> return them as a dictionary\n",
    "    if len(data)==4:\n",
    "         return [{'price':int(price),'locali': int(data[0]), 'superficie': int(data[1]), \"bagni\": int(data[2]), \"piano\": int(data[3])}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threadExtract(url):\n",
    "    \"\"\"\n",
    "    This function is getting html content, scrapping data and saving it into our database.\n",
    "    Input: String: \"url\" \n",
    "    \"\"\"\n",
    "    logging.info('extracting' + url)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    data_dict = scrap_data(soup) #output should be a dictionary\n",
    "    \n",
    "    collection = 'flats'\n",
    "    col_url = base + '/databases/' + adm_database + \"/collections/\" + collection +'/?apiKey=' + my_key\n",
    "\n",
    "    # Pushing data into database\n",
    "    payload = json.dumps(data_dict)\n",
    "    response = requests.post(col_url, data=payload, headers=headers)\n",
    "\n",
    "    logging.info(\"Done extracting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thread-based parallelism :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links=[] # list with links used while retrieving data\n",
    "\n",
    "stop = False\n",
    "i = 1 \n",
    "while stop == False:\n",
    "    # Loading the initial web-page\n",
    "    content = requests.get(\"https://www.immobiliare.it/vendita-case/roma/?criterio=rilevanza&pag=\"+str(i))\n",
    "    soup = BeautifulSoup(content.text, 'html.parser')\n",
    "    \n",
    "    # Scrapping data from each link from the initial website until we get 10000 links\n",
    "    for link in soup.find_all('a', href=True):\n",
    "        url = link['href']\n",
    "        if url.startswith('https://www.immobiliare.it/') and url.endswith('.html'):\n",
    "            try:\n",
    "                threadExtract(url)\n",
    "                links.append(url)\n",
    "                if len(links >= 10000): stop = True\n",
    "            except: continue\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display what is inside the database\n",
    "response = requests.get(col_url)\n",
    "result = json.loads(response.text)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert data into matrix\n",
    "dataset1 = np.matrix(list(map(lambda x:list(x.values())[1:], result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset1) #number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
