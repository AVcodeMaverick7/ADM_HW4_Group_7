{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping data (old code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen as ureq\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns =['price', 'locali', 'superficie', 'bagni','piano'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "links=[]\n",
    "\n",
    "for i in range(1,20):\n",
    "    content = requests.get(\"https://www.immobiliare.it/vendita-case/roma/?criterio=rilevanza&pag=\"+str(i))\n",
    "    soup = BeautifulSoup(content.text, 'html.parser')\n",
    "    for link in soup.find_all('a', href=True):\n",
    "        url = link['href']\n",
    "        if url.startswith('https://www.immobiliare.it/') and url.endswith('.html'):\n",
    "            links.append(url)\n",
    "            scrap_data(url)\n",
    "\n",
    "for i in range(len(links)):\n",
    "    content = requests.get(links[i])\n",
    "    soup=BeautifulSoup(content.text,'html.parser')\n",
    "    p = soup.find_all('li',class_='features__price')[0].get_text()\n",
    "    p = p.replace(\"€\", \"\")\n",
    "    p = p.replace(\" \", \"\")\n",
    "    p = p.replace(\".\", \"\")\n",
    "    l1 = Soup.find_all('ul','list-inline list-piped features__list')[0].get_text()\n",
    "    l1 = l1.replace('m2','')\n",
    "    numbers = re.compile('\\d+(?:\\.\\d+)?')\n",
    "    l1 = numbers.findall(l1)\n",
    "    if len(l1)==4:\n",
    "         i = [{'price':int(p),'locali': int(l1[0]), 'superficie': int(l1[1]), \"bagni\": int(l1[2]), \"piano\": int(l1[3])}]\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content = requests.get(links[0])\n",
    "# soup = BeautifulSoup(content.text, 'html.parser')\n",
    "# features = soup.find_all(class_=[\"list-inline list-piped features__list\"])[0].get_text()\n",
    "# features = features.replace('\\xa0', \"\")\n",
    "# tmp = features.split(\"locali\")\n",
    "# locali = int(tmp[0])\n",
    "# superficie = int(tmp[1].split('m2superficie')[0]) \n",
    "# bagni, piano = map(int, tmp[1].split('m2superficie')[1].split()[0].split(\"bagni\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mongo_DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen as ureq\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adm_hm4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient()\n",
    "my_key = \"AnqLqo5TT9JDfzfqKrDUEYUqJ6HWZJy8\"\n",
    "base = \"https://api.mlab.com/api/1\"\n",
    "url_db = base + \"/databases?apiKey=\" + my_key\n",
    "response = requests.get(url_db)\n",
    "databases = json.loads(response.text)\n",
    "adm_database = databases[0]\n",
    "adm_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure\n",
    "headers = {'content-type':'application/json'}\n",
    "\n",
    "# test data\n",
    "# flat_data = [{'price':100,'locali': 2, 'superficie': 1, \"bagni\": 2, \"piano\": 5}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I manually created the collection 'flats' in \"adm_hm4\" database\n",
    "collection = 'flats'\n",
    "col_url = base + '/databases/' + adm_database + \"/collections/\" + collection +'/?apiKey=' + my_key\n",
    "\n",
    "# Pushing data into database\n",
    "# payload = json.dumps(flat_data)\n",
    "# response = requests.post(col_url, data=payload, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking what is inside our database\n",
    "response = requests.get(col_url)\n",
    "result = json.loads(response.text)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to extract data from websites and push into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_data(soup):\n",
    "    price = soup.find_all('li',class_='features__price')[0].get_text()\n",
    "    price = price.replace(\"€\", \"\").replace(\" \", \"\").replace(\".\", \"\")\n",
    "    \n",
    "    data = soup.find_all('ul','list-inline list-piped features__list')[0].get_text()\n",
    "    data = data.replace('m2','')\n",
    "    numbers = re.compile('\\d+(?:\\.\\d+)?')\n",
    "    data = numbers.findall(data)\n",
    "    if len(data)==4:\n",
    "         return [{'price':int(price),'locali': int(data[0]), 'superficie': int(data[1]), \"bagni\": int(data[2]), \"piano\": int(data[3])}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extractInfo is function to scrap html ; output --> dictionary\n",
    "import logging\n",
    "\n",
    "def threadExtract(url):\n",
    "    logging.info('extracting' + url)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    data_dict = scrap_data(soup) #output should be a dictionary\n",
    "    \n",
    "    collection = 'flats'\n",
    "    col_url = base + '/databases/' + adm_database + \"/collections/\" + collection +'/?apiKey=' + my_key\n",
    "\n",
    "    # Pushing data into database\n",
    "    payload = json.dumps(data_dict)\n",
    "    response = requests.post(col_url, data=payload, headers=headers)\n",
    "\n",
    "    logging.info(\"Done extracting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links=[]\n",
    "\n",
    "stop = False\n",
    "i = 1 \n",
    "while stop == False:\n",
    "    content = requests.get(\"https://www.immobiliare.it/vendita-case/roma/?criterio=rilevanza&pag=\"+str(i))\n",
    "    soup = BeautifulSoup(content.text, 'html.parser')\n",
    "    \n",
    "    for link in soup.find_all('a', href=True):\n",
    "        url = link['href']\n",
    "        if url.startswith('https://www.immobiliare.it/') and url.endswith('.html'):\n",
    "            try:\n",
    "                threadExtract(url)\n",
    "                links.append(url)\n",
    "                if len(links >= 10000): stop = True\n",
    "            except: continue\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display what is inside the database\n",
    "response = requests.get(col_url)\n",
    "result = json.loads(response.text)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
